"""
Qdrant Vector Database Client
=============================
High-performance vector database client for El-Harezmi RAG architecture.

Features:
- Dense vector search (semantic similarity)
- Sparse vector search (BM25 keyword matching)
- Hybrid search with RRF fusion
- Advanced metadata filtering
- Product family filtering
- Intent-aware retrieval

Migration: Replaces ChromaDB for better performance and filtering.

Usage:
    client = QdrantDBClient()
    results = client.search(
        query_vector=embeddings,
        top_k=10,
        product_filter="EABC",
        intent_filter=["CONFIGURATION", "PROCEDURE"]
    )
"""
import os
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime

logger = logging.getLogger(__name__)

# Qdrant client - lazy import to handle missing dependency gracefully
try:
    from qdrant_client import QdrantClient as Qdrant
    from qdrant_client.models import (
        Distance, VectorParams, PointStruct,
        Filter, FieldCondition, MatchValue, MatchAny,
        SparseVectorParams, SparseIndexParams,
        PayloadSchemaType, TextIndexParams, TokenizerType,
        OptimizersConfigDiff, HnswConfigDiff,
        SearchParams, QuantizationSearchParams,
        ScoredPoint, UpdateStatus
    )
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    logger.warning("qdrant-client not installed. Run: pip install qdrant-client")


# =============================================================================
# CONFIGURATION
# =============================================================================

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", "6333"))
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION", "desoutter_docs_v2")
VECTOR_SIZE = 384  # all-MiniLM-L6-v2 embedding dimension


@dataclass
class SearchResult:
    """Search result with metadata"""
    id: str
    score: float
    text: str
    metadata: Dict[str, Any]


class QdrantDBClient:
    """
    Qdrant client for El-Harezmi RAG architecture.
    
    Provides:
    - Collection management
    - Document ingestion with metadata
    - Hybrid search (dense + sparse)
    - Intent-aware filtering
    - Product family filtering
    """
    
    def __init__(
        self,
        host: str = QDRANT_HOST,
        port: int = QDRANT_PORT,
        collection_name: str = COLLECTION_NAME
    ):
        """
        Initialize Qdrant client.
        
        Args:
            host: Qdrant server host
            port: Qdrant server port
            collection_name: Name of the collection to use
        """
        if not QDRANT_AVAILABLE:
            raise ImportError(
                "qdrant-client is not installed. "
                "Install with: pip install qdrant-client"
            )
        
        self.host = host
        self.port = port
        self.collection_name = collection_name
        
        logger.info(f"Connecting to Qdrant at {host}:{port}")
        self.client = Qdrant(host=host, port=port, timeout=30)
        
        # Verify connection
        try:
            self.client.get_collections()
            logger.info("‚úÖ Qdrant connection successful")
        except Exception as e:
            logger.error(f"‚ùå Qdrant connection failed: {e}")
            raise
    
    def ensure_collection(self) -> bool:
        """
        Create collection if it doesn't exist.
        
        Returns:
            True if collection exists or was created
        """
        try:
            # Check if collection exists
            collections = self.client.get_collections().collections
            exists = any(c.name == self.collection_name for c in collections)
            
            if exists:
                logger.info(f"Collection '{self.collection_name}' already exists")
                return True
            
            # Create collection with El-Harezmi schema
            logger.info(f"Creating collection '{self.collection_name}'...")
            
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config={
                    "dense": VectorParams(
                        size=VECTOR_SIZE,
                        distance=Distance.COSINE
                    )
                },
                # Sparse vectors for BM25 (optional, can be added later)
                # sparse_vectors_config={
                #     "sparse": SparseVectorParams(
                #         index=SparseIndexParams(on_disk=False)
                #     )
                # },
                optimizers_config=OptimizersConfigDiff(
                    indexing_threshold=10000,
                    memmap_threshold=50000
                ),
                hnsw_config=HnswConfigDiff(
                    m=16,
                    ef_construct=100,
                    full_scan_threshold=10000
                )
            )
            
            # Create payload indexes for fast filtering
            self._create_payload_indexes()
            
            logger.info(f"‚úÖ Collection '{self.collection_name}' created")
            return True
            
        except Exception as e:
            logger.error(f"Failed to ensure collection: {e}")
            return False
    
    def _create_payload_indexes(self):
        """Create indexes on frequently filtered payload fields"""
        indexed_fields = [
            ("product_family", PayloadSchemaType.KEYWORD),
            ("product_model", PayloadSchemaType.KEYWORD),
            ("document_type", PayloadSchemaType.KEYWORD),
            ("chunk_type", PayloadSchemaType.KEYWORD),
            ("source", PayloadSchemaType.KEYWORD),
            ("esde_code", PayloadSchemaType.KEYWORD),
            ("error_code", PayloadSchemaType.KEYWORD),
            ("contains_procedure", PayloadSchemaType.BOOL),
            ("contains_table", PayloadSchemaType.BOOL),
            ("contains_error_code", PayloadSchemaType.BOOL),
        ]
        
        for field_name, field_type in indexed_fields:
            try:
                self.client.create_payload_index(
                    collection_name=self.collection_name,
                    field_name=field_name,
                    field_schema=field_type
                )
                logger.debug(f"Created index on '{field_name}'")
            except Exception as e:
                # Index might already exist
                logger.debug(f"Index on '{field_name}' might already exist: {e}")
    
    def upsert(
        self,
        documents: List[Dict[str, Any]],
        batch_size: int = 100
    ) -> Tuple[int, int]:
        """
        Insert or update documents.
        
        Args:
            documents: List of dicts with 'id', 'text', 'embedding', 'metadata'
            batch_size: Number of documents per batch
            
        Returns:
            Tuple of (success_count, error_count)
        """
        success_count = 0
        error_count = 0
        
        # Process in batches
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            points = []
            
            for doc in batch:
                try:
                    point = PointStruct(
                        id=doc['id'],
                        vector={"dense": doc['embedding']},
                        payload={
                            "text": doc.get('text', ''),
                            **doc.get('metadata', {})
                        }
                    )
                    points.append(point)
                except Exception as e:
                    logger.error(f"Error preparing document {doc.get('id')}: {e}")
                    error_count += 1
            
            # Upsert batch
            try:
                result = self.client.upsert(
                    collection_name=self.collection_name,
                    points=points,
                    wait=True
                )
                if result.status == UpdateStatus.COMPLETED:
                    success_count += len(points)
                else:
                    error_count += len(points)
            except Exception as e:
                logger.error(f"Batch upsert failed: {e}")
                error_count += len(points)
        
        logger.info(f"Upserted {success_count} documents ({error_count} errors)")
        return success_count, error_count
    
    def search(
        self,
        query_vector: List[float],
        top_k: int = 10,
        product_filter: Optional[str] = None,
        intent_filter: Optional[List[str]] = None,
        document_type_filter: Optional[str] = None,
        score_threshold: float = 0.0
    ) -> List[SearchResult]:
        """
        Search for similar documents with optional filtering.
        
        Args:
            query_vector: Query embedding vector
            top_k: Number of results to return
            product_filter: Filter by product family (e.g., "EABC", "ERS")
            intent_filter: Filter by intent relevance (e.g., ["CONFIGURATION"])
            document_type_filter: Filter by document type
            score_threshold: Minimum similarity score
            
        Returns:
            List of SearchResult objects
        """
        # Build filter conditions
        must_conditions = []
        
        if product_filter:
            must_conditions.append(
                FieldCondition(
                    key="product_family",
                    match=MatchValue(value=product_filter.upper())
                )
            )
        
        if document_type_filter:
            must_conditions.append(
                FieldCondition(
                    key="document_type",
                    match=MatchValue(value=document_type_filter)
                )
            )
        
        # Intent filter - match any of the provided intents
        should_conditions = []
        if intent_filter:
            for intent in intent_filter:
                should_conditions.append(
                    FieldCondition(
                        key="intent_relevance",
                        match=MatchAny(any=[intent])
                    )
                )
        
        # Construct filter
        search_filter = None
        if must_conditions or should_conditions:
            search_filter = Filter(
                must=must_conditions if must_conditions else None,
                should=should_conditions if should_conditions else None
            )
        
        # Execute search
        try:
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=("dense", query_vector),
                query_filter=search_filter,
                limit=top_k,
                score_threshold=score_threshold,
                with_payload=True
            )
            
            # Convert to SearchResult objects
            search_results = []
            for point in results:
                payload = point.payload or {}
                search_results.append(SearchResult(
                    id=str(point.id),
                    score=point.score,
                    text=payload.get('text', ''),
                    metadata={k: v for k, v in payload.items() if k != 'text'}
                ))
            
            logger.debug(f"Search returned {len(search_results)} results")
            return search_results
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []
    
    def search_hybrid(
        self,
        query_vector: List[float],
        query_text: str,
        top_k: int = 10,
        product_filter: Optional[str] = None,
        semantic_weight: float = 0.7,
        bm25_weight: float = 0.3
    ) -> List[SearchResult]:
        """
        Hybrid search combining semantic and keyword matching.
        
        Note: Full BM25 requires sparse vectors. This is a simplified version
        using payload text matching for now.
        
        Args:
            query_vector: Query embedding vector
            query_text: Original query text for keyword matching
            top_k: Number of results
            product_filter: Product family filter
            semantic_weight: Weight for semantic similarity (0-1)
            bm25_weight: Weight for keyword matching (0-1)
            
        Returns:
            List of SearchResult objects with combined scores
        """
        # For now, use dense search only
        # TODO: Add sparse vector search when implemented
        return self.search(
            query_vector=query_vector,
            top_k=top_k,
            product_filter=product_filter
        )
    
    def delete_collection(self) -> bool:
        """Delete the collection"""
        try:
            self.client.delete_collection(self.collection_name)
            logger.info(f"Deleted collection '{self.collection_name}'")
            return True
        except Exception as e:
            logger.error(f"Failed to delete collection: {e}")
            return False
    
    def get_collection_info(self) -> Optional[Dict]:
        """Get collection statistics"""
        try:
            info = self.client.get_collection(self.collection_name)
            return {
                "name": self.collection_name,
                "vectors_count": info.vectors_count,
                "points_count": info.points_count,
                "status": info.status.name,
                "optimizer_status": info.optimizer_status.name if info.optimizer_status else None
            }
        except Exception as e:
            logger.error(f"Failed to get collection info: {e}")
            return None
    
    def health_check(self) -> bool:
        """Check if Qdrant is healthy"""
        try:
            self.client.get_collections()
            return True
        except Exception:
            return False


# =============================================================================
# SINGLETON INSTANCE
# =============================================================================

_qdrant_client: Optional[QdrantDBClient] = None


def get_qdrant_client() -> QdrantDBClient:
    """Get singleton Qdrant client instance"""
    global _qdrant_client
    
    if _qdrant_client is None:
        _qdrant_client = QdrantDBClient()
    
    return _qdrant_client


# =============================================================================
# CLI TEST
# =============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("=" * 60)
    print("QDRANT CLIENT TEST")
    print("=" * 60)
    
    try:
        client = QdrantDBClient()
        print(f"‚úÖ Connected to Qdrant at {QDRANT_HOST}:{QDRANT_PORT}")
        
        # Ensure collection
        if client.ensure_collection():
            print(f"‚úÖ Collection '{COLLECTION_NAME}' ready")
        
        # Get info
        info = client.get_collection_info()
        if info:
            print(f"üìä Collection info:")
            for key, value in info.items():
                print(f"   {key}: {value}")
        
        # Health check
        if client.health_check():
            print("‚úÖ Health check passed")
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
