# TODO: Next Session

## Status: Source Citation Enhancement COMPLETE âœ…

We have successfully fixed the page number extraction issue and re-ingested all documents. The RAG system now has accurate metadata.

## Next Priorities

### 1. Phase 2: Retrieval Enhancement (Week 1)
- [ ] **Hybrid Retrieval:** Implement `rank_bm25` to combine keyword search with vector search.
- [ ] **Re-Ranking:** Implement a re-ranker (e.g., Cross-Encoder) to filter top-k results for better relevance.
- [ ] **Metadata Filtering:** Add filters for `product_line` and `doc_type` in the API query.

### 2. Phase 3: Dynamic Prompts (Week 2)
- [ ] **Intent Detection:** Refine the `IntentDetector` to better classify queries (Troubleshooting vs. Specs).
- [ ] **Prompt Templates:** Create specific system prompts for each intent type.

## Technical Debt / Maintenance
- [ ] **Unit Tests:** Add more comprehensive unit tests for `DocumentProcessor`.
- [ ] **CI/CD:** Consider setting up a GitHub Action for automated testing.

---

## ğŸ« PHASE 4: Freshdesk Ticket Scraper Entegrasyonu âœ… COMPLETE

**Kaynak:** Desoutter Support Portal (Freshdesk) - GerÃ§ek mÃ¼ÅŸteri sorularÄ± ve destek Ã§Ã¶zÃ¼mleri
**DeÄŸer:** Q&A formatÄ±nda gerÃ§ek dÃ¼nya sorunlarÄ± + PDF attachment iÃ§erikleri
**Durum:** âœ… TÃ¼m kod tamamlandÄ± - Test ve kullanÄ±m aÅŸamasÄ±nda

### OluÅŸturulan Dosyalar
- [x] `src/scraper/ticket_scraper.py` - Async ticket scraper (aiohttp)
- [x] `src/database/models.py` - TicketModel, TicketComment, TicketAttachment
- [x] `scripts/scrape_tickets.py` - Ticket scraping script
- [x] `scripts/ingest_tickets.py` - Ticket'larÄ± RAG'a ekleme

### YapÄ±lan DeÄŸiÅŸiklikler
- [x] `requirements.txt` - `pdfplumber`, `PyPDF2` eklendi
- [x] `src/database/mongo_client.py` - `tickets` collection desteÄŸi
- [x] `config/settings.py` - Freshdesk credentials config
- [x] `src/database/__init__.py` - TicketModel exports

### KullanÄ±m

```bash
# 1. Environment variables ayarla
export FRESHDESK_EMAIL="your-email@company.com"
export FRESHDESK_PASSWORD="your-password"

# 2. Test scrape (son 3 sayfa)
python scripts/scrape_tickets.py --test

# 3. Son 50 sayfa scrape
python scripts/scrape_tickets.py --pages 50

# 4. Tam scrape (1675 sayfa)
python scripts/scrape_tickets.py --full

# 5. PDF indirmeden hÄ±zlÄ± scrape
python scripts/scrape_tickets.py --pages 100 --no-pdf

# 6. YarÄ±da kaldÄ±ysa devam et
python scripts/scrape_tickets.py --resume

# 7. Ticket'larÄ± RAG'a ekle
python scripts/ingest_tickets.py

# 8. Sadece Ã§Ã¶zÃ¼lmÃ¼ÅŸ ticket'larÄ± ekle
python scripts/ingest_tickets.py --resolved-only
```

### Data Locations
- Ticket IDs: `data/tickets/ticket_ids.json`
- Checkpoint: `data/tickets/checkpoint.json`
- RAG Export: `data/tickets/tickets_rag.json`
- Downloaded PDFs: `data/ticket_pdfs/`

---

## ğŸš© YARIN YAPILACAKLAR

- [ ] Son 200 ticketÄ± Ã§ek
- [ ] Son 200 ticketÄ± Ã¶niÅŸlemeden geÃ§ir
- [ ] Son 200 ticketÄ± vector db'ye ekle
- [ ] TÃ¼m deÄŸiÅŸiklikleri commit et
 